{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4cf52a-710c-4f18-aa52-ad358b9a162a",
   "metadata": {},
   "source": [
    "May 2022, Claire Valva\n",
    "## data processing file (BAM/SAM/energy cycle):\n",
    "In this file I process some era5 data for later analysis, specifically decomposing into Reynolds average and eddy terms. The variables we are interested in looking at (using the definitions from Thomspon and Woodworth 2014), brackets denote Reynold's average, primes denote eddy comp:\n",
    "- Southern Annular Mode (SAM): defined as the leading PCA component of zonal mean zonal wind (in the SH)\n",
    "- Baroclinic Annular Mode (BAM): defined as the leading PCA component of EKE ($[u'^2 + v'^2]/2$) in the SH.\n",
    "- vertical wave heat flux: $[w'T']$\n",
    "- eddy momentum flux: $[u'v']$\n",
    "- meridional wave heat flux: $[v'T']$\n",
    "- zonal mean KE: $[u]^2/2$\n",
    "- meridional EP flux: $-\\rho \\cos (\\varphi) [u'v']$\n",
    "    - we can use a reference density profile of $\\rho = e^{-z/H}$ where $H = 6.8 km$ and is the scale height\n",
    "- vertical EP flux: $f\\rho a \\cos (\\varphi) [u'\\theta']/[\\theta]_z$\n",
    "    - we will use $6,371 km$ as the raidius of the earth\n",
    "    - recall that the formula to calculate potential temperature is: $\\theta = (p_0/p)^{R/c_p} T$, and we estimate $R/c_p = 0.286$.\n",
    "- total heat flux: $c_p T + L_v q$ \n",
    "    - to estimate $L$ we will use the relation in chapter 18, appendix A of Vallis so that $L_v(T) = (2.501 \\times 10^6 - 2359 T) J kg^{-1}$ where $T$ is in Celsius.\n",
    "    - We will use $c_p =  1003 J kg^{-1} K^{-1}$\n",
    "- CAPE\n",
    "- will also want to look at the fourier components, is there always a sharp/\"unique\" time scale at ~25 days?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa21ef11-7cae-489b-9d3c-1ee424e971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a21580-1a08-4ddf-aafd-441bbcb4ccbe",
   "metadata": {},
   "source": [
    "I borrowed some of this code from Dave, loading the data this way is much better than way I was originally doing. (Find the original file in this repo: https://github.com/dsconnelly/brewson).\n",
    "\n",
    "The monthly means from era5 are 'ds633.1' but the full temporal data is found under file name 'ds633.0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6def19e6-f176-4201-9768-00a331dfbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose if want to use daily or monthly data (daily might take a prohibitively long time...)\n",
    "monthly = True\n",
    "if monthly:\n",
    "    era_dir = '/gpfs/fs1/collections/rda/data/ds633.1/e5.moda.an.pl'\n",
    "    era_dir_cape = '/gpfs/fs1/collections/rda/data/ds633.1/e5.moda.an.sfc/'\n",
    "else:\n",
    "    era_dir = '/gpfs/fs1/collections/rda/data/ds633.0/e5.oper.an.pl'\n",
    "    era_dir_cape = '/gpfs/fs1/collections/rda/data/ds633.0/e5.oper.an.sfc'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ec81a4-8007-4d49-86b1-b4cca148e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 years of ERA5 data, starting with 1979 and ending with 2021.\n",
      "Found 215 files out of an expected 215.\n"
     ]
    }
   ],
   "source": [
    "years = [int(x) for x in sorted(os.listdir(era_dir))]\n",
    "\n",
    "print(f'Found {len(years)} years of ERA5 data, starting with {years[0]} and ending with {years[-1]}.')\n",
    "\n",
    "names = ['u', 'v', 'w', 'T', 'q']\n",
    "\n",
    "ds_fnames = []\n",
    "for year in years:\n",
    "    year_dir = f'{era_dir}/{year}'\n",
    "    fnames = [x for x in os.listdir(year_dir) if x.endswith('nc')]\n",
    "    \n",
    "    for name in names:\n",
    "        fname = [x for x in fnames if f'_{name.lower()}.' in x][0]\n",
    "        ds_fnames.append(f'{year_dir}/{fname}')\n",
    "        \n",
    "print(f'Found {len(ds_fnames)} files out of an expected {len(years) * len(names)}.')\n",
    "\n",
    "# grab CAPE also\n",
    "ds_fnames_cape = []\n",
    "name = 'cape'\n",
    "for year in years:\n",
    "    year_dir = f'{era_dir_cape}/{year}'\n",
    "    fnames_cape = [x for x in os.listdir(year_dir) if x.endswith('nc')]\n",
    "    fname_cape = [x for x in fnames_cape if f'_{name.lower()}.' in x][0]\n",
    "    ds_fnames.append(f'{year_dir}/{fname_cape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf5fde5-1227-4ee4-b6bf-477887089d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 721, longitude: 1440, time: 516, z: 37)\n",
       "Coordinates:\n",
       "  * latitude   (latitude) float64 1.571 1.566 1.562 ... -1.562 -1.566 -1.571\n",
       "  * longitude  (longitude) float64 0.0 0.25 0.5 0.75 ... 359.0 359.2 359.5 359.8\n",
       "  * time       (time) datetime64[ns] 1979-01-01 1979-02-01 ... 2021-12-01\n",
       "  * z          (z) float64 4.697e+04 4.226e+04 3.95e+04 ... 348.8 172.2 -0.0\n",
       "Data variables:\n",
       "    cape       (time, latitude, longitude) float32 dask.array<shape=(516, 721, 1440), chunksize=(12, 721, 1440)>\n",
       "    q          (time, z, latitude, longitude) float32 dask.array<shape=(516, 37, 721, 1440), chunksize=(12, 37, 721, 1440)>\n",
       "    T          (time, z, latitude, longitude) float32 dask.array<shape=(516, 37, 721, 1440), chunksize=(12, 37, 721, 1440)>\n",
       "    u          (time, z, latitude, longitude) float32 dask.array<shape=(516, 37, 721, 1440), chunksize=(12, 37, 721, 1440)>\n",
       "    v          (time, z, latitude, longitude) float32 dask.array<shape=(516, 37, 721, 1440), chunksize=(12, 37, 721, 1440)>\n",
       "    w          (time, z, latitude, longitude) float32 dask.array<shape=(516, 37, 721, 1440), chunksize=(12, 37, 721, 1440)>\n",
       "    p          (z) float64 100.0 200.0 300.0 500.0 ... 9.5e+04 9.75e+04 1e+05\n",
       "    rho        (z) float64 0.001 0.002 0.003 0.005 ... 0.925 0.95 0.975 1.0\n",
       "Attributes:\n",
       "    DATA_SOURCE:          ECMWF: https://cds.climate.copernicus.eu, Copernicu...\n",
       "    NETCDF_CONVERSION:    CISL RDA: Conversion from ECMWF GRIB 1 data to netC...\n",
       "    NETCDF_VERSION:       4.6.1\n",
       "    CONVERSION_PLATFORM:  Linux casper04 3.10.0-693.21.1.el7.x86_64 #1 SMP We...\n",
       "    CONVERSION_DATE:      Fri Nov  8 18:03:42 MST 2019\n",
       "    Conventions:          CF-1.6\n",
       "    NETCDF_COMPRESSION:   NCO: Precision-preserving compression to netCDF4/HD...\n",
       "    history:              Fri Nov  8 18:03:52 2019: ncks -4 --ppc default=7 e...\n",
       "    NCO:                  netCDF Operators version 4.7.9 (Homepage = http://n..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with xr.open_mfdataset(ds_fnames, combine='by_coords') as ds:\n",
    "    ds = ds.rename({\n",
    "        'level' : 'z',\n",
    "        'U' : 'u',\n",
    "        'V' : 'v',\n",
    "        'W' : 'w',\n",
    "        'Q' : 'q',\n",
    "        'CAPE' : 'cape'\n",
    "    }).drop('utc_date')\n",
    "    \n",
    "    p = (100 * ds['z']).assign_attrs(units='Pa')\n",
    "    lat = (np.pi * ds['latitude'] / 180).assign_attrs(units='radians_north')\n",
    "    \n",
    "    H, p_surf = 6800, p[-1]\n",
    "    z = (-H * np.log(p / p_surf)).assign_attrs(units='meters')\n",
    "    rho = np.exp(-z / H)\n",
    "    \n",
    "    ds['p'], ds['rho'] = p, rho\n",
    "    ds = ds.assign_coords(z=z, latitude=lat)\n",
    "    \n",
    "    # reduce to daily means (unecessary if use monthly rather than daily)\n",
    "    if not monthly:\n",
    "        ds = ds.groupby(\"time.dayofyear\").mean(\"time\")\n",
    "    \n",
    "    display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abdadf94-e28b-4fb8-b4d8-99a4dffe3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down vars as arrays\n",
    "p, lat, rho = ds['p'], ds['latitude'], ds['rho']\n",
    "u, v, w = ds['u'], ds['v'], ds['w']\n",
    "T, q = ds['T'], ds['q']\n",
    "cape = ds['cape']\n",
    "\n",
    "# compute potential temp:\n",
    "theta = T * ((p_surf / p) ** 0.286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3180dea1-998a-4f2f-aa27-4c4110924f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute total heat flux\n",
    "def comp_Lv(temp):\n",
    "    temp_c = temp - 273.12\n",
    "    Lv = 2.510e6 - 2359*temp_c\n",
    "    return Lv\n",
    "\n",
    "Lv = comp_Lv(T)\n",
    "cp = 1003\n",
    "hflux = cp*T - Lv*q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a3ced5-eaae-4ab4-930f-6dd3d98cbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take zonal means:\n",
    "u_bar = u.mean('longitude')\n",
    "v_bar = v.mean('longitude')\n",
    "w_bar = w.mean('longitude')\n",
    "T_bar = T.mean('longitude')\n",
    "theta_bar = theta.mean('longitude')\n",
    "hflux_bar = hflux.mean('longitude')\n",
    "\n",
    "# get primes\n",
    "v_prime = v - v_bar\n",
    "u_prime = u - u_bar\n",
    "w_prime = w - w_bar\n",
    "T_prime = T - T_bar\n",
    "theta_prime = theta - theta_bar\n",
    "hflux_prime = hflux - hflux_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30232625-51dc-472c-a81e-23e8bf99eb18",
   "metadata": {},
   "source": [
    "compute the following:\n",
    "- EKE $[u'^2 + v'^2]/2$\n",
    "- vertical wave heat flux: $[w'T']$\n",
    "- eddy momentum flux: $[u'v']$\n",
    "- meridional wave heat flux: $[v'T']$\n",
    "- zonal mean KE: $[u]^2/2$\n",
    "- meridional EP flux: $-\\rho \\cos (\\varphi) [u'v']$\n",
    "    - we can use a reference density profile of $\\rho = e^{-z/H}$ where $H = 6.8 km$ and is the scale height\n",
    "- vertical EP flux: $f\\rho a \\cos (\\varphi) [u'\\theta']/[\\theta]_z$\n",
    "    - we will use $6,371 km$ as the raidius of the earth\n",
    "    - recall that the formula to calculate potential temperature is: $\\theta = (p_0/p)^{R/c_p} T$, and we estimate $R/c_p = 0.286$.\n",
    "- total heat flux: $c_p T + L_v q$ \n",
    "    - to estimate $L$ we will use the relation in chapter 18, appendix A of Vallis so that $L_v(T) = (2.501 \\times 10^6 - 2359 T) J kg^{-1}$ where $T$ is in Celsius.\n",
    "    - We will use $c_p =  1003 J kg^{-1} K^{-1}$\n",
    "- CAPE\n",
    "- the fourier components, is there always a sharp/\"unique\" time scale at ~25 days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c0bf6b-a6d0-4f6c-ab34-c5985129a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some other quantities\n",
    "EKE = ((u_prime**2 + v_prime**2)/2)\n",
    "wpTp = (w_prime*T_prime)\n",
    "upvp = (u_prime*v_prime)\n",
    "zonalKE = u_bar**2/2\n",
    "vpTp = v_prime*T_prime\n",
    "vphfluxp = v_prime*hflux_prime\n",
    "\n",
    "a = 6.37e6\n",
    "Omega = 7.292e-5\n",
    "f = 2 * Omega * np.sin(lat)\n",
    "\n",
    "meridEPflux = -rho*np.cos(lat)*upvp\n",
    "upthetap = (u_prime*theta_prime)\n",
    "vertEPflux = f*rho*a*np.cos(lat)*upthetap/(theta_bar.mean('z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b70724b-5f4f-4f35-ad60-695e08b55ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newds = xr.Dataset({\n",
    "    'u' : u,\n",
    "    'v' : v,\n",
    "    'EKE' : EKE,\n",
    "    'KE_zonal' : zonalKE,\n",
    "    'wpTp' : wpTp,\n",
    "    'upvp' : upvp,\n",
    "    'EP_merid' : meridEPflux,\n",
    "    'EP_vert' :  vertEPflux,\n",
    "    'cape' : cape,\n",
    "    'vpTp' : vpTp,\n",
    "    'vpheatp': vphfluxp}).mean('longitude').rename({'z' : 'pressure'})\n",
    "\n",
    "# convert back to original height and lat coords\n",
    "p = (p_surf * np.exp(-newds['pressure'] / H) / 100).assign_attrs(units='hPa')\n",
    "lat = (180 * newds['latitude'] / np.pi).assign_attrs(units='degrees_north')\n",
    "newds = newds.assign_coords(pressure=p, latitude=lat).drop('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c55e40e0-2138-49cc-bc31-771022bd35dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (latitude: 721, pressure: 37, time: 516)\n",
       "Coordinates:\n",
       "  * latitude  (latitude) float64 90.0 89.75 89.5 89.25 ... -89.5 -89.75 -90.0\n",
       "  * time      (time) datetime64[ns] 1979-01-01 1979-02-01 ... 2021-12-01\n",
       "  * pressure  (pressure) float64 1.0 2.0 3.0 5.0 7.0 ... 925.0 950.0 975.0 1e+03\n",
       "Data variables:\n",
       "    u         (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    v         (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    EKE       (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    KE_zonal  (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    wpTp      (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    upvp      (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    EP_merid  (pressure, latitude, time) float64 dask.array<shape=(37, 721, 516), chunksize=(37, 721, 12)>\n",
       "    EP_vert   (latitude, pressure, time) float64 dask.array<shape=(721, 37, 516), chunksize=(721, 37, 12)>\n",
       "    cape      (time, latitude) float32 dask.array<shape=(516, 721), chunksize=(12, 721)>\n",
       "    vpTp      (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>\n",
       "    vpheatp   (time, pressure, latitude) float32 dask.array<shape=(516, 37, 721), chunksize=(12, 37, 721)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(newds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f845f30-e0ef-44b7-bd7e-caff8ccfc92d",
   "metadata": {},
   "source": [
    "note that the saving to netcdf is where the computations are actually completed, it is not particularly fast (a few hours) and takes a substantial amount of memory. (I believe about 115 GB at most.) However, the total file size of the completed file is less than a GB which is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f3e68e-c05a-4661-b945-89039e0e8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "newds.to_netcdf(\"/glade/u/home/cvalva/atmoclass/eddy_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96dd7d8-45ca-49e0-894f-1d856c2e264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"completed saving and processing\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pangeo (2019.09.12 - py3.7)",
   "language": "python",
   "name": "pangeo-2019.09.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
